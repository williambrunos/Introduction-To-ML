{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/williambrunos/Introduction-To-ML/blob/main/Class_2/Class_2_2/Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Árvores de decisão\n",
        "\n",
        "Árvores de decisão são estruturas de dados baseados em \"se...então\" para classificar ou realizar predições (regressões) de dados numéricos. Em geral, estas árvores são baseadas em perguntas, e as respostas a essas perguntas são responsáveis por classificar a resposta.\n",
        "\n",
        "Ademais, uma ávore de decisão não necessariamente precisa ser baseada em uma única pergunta, e as respostas podem ser dados categóricos ou numéricos.\n",
        "\n",
        "Para cada amostra de dados, descemos na árvore desde o nó raiz até chegarmos a um ponto em que não se faz mais necessário realizar nenhuma \"pergunta\", e é aí em que as classificações são feitas.\n",
        "\n",
        "## Algoritmo\n",
        "\n",
        "O algoritmo se concentra em: \n",
        "\n",
        "- Dadas as características do dataset e das observações, observar o quão bem cada uma divide os dados entre os labels conhecidos. Uma divisão feita de forma não perfeita, ou seja, com resultados de labels diferentes, é chamada de divisão impura.\n",
        "\n",
        "- Para determinar qual divisão é melhor, temos de ter um meio de calcular a impureza de cada divisão.\n",
        "\n",
        "$$gini=1-(probability\\;of\\;yes)^2 - (probability\\;of\\;no)^2$$\n",
        "\n",
        "- É comum que divisões baseadas em alguma tabela (característica) resultem em nós com quantidades de observações diferentes. Portanto, para calcular a impureza (gini) daquela divisão baseada na característica em questão, tomamos a quantidade de observações nos nós divida pela quantidade total de observações nos dois nós e realizamos uma média ponderada destas divisões com base nos valores de impurezas descobertos.\n",
        "\n",
        "- A característica que possuir o menor índice de Gini é então utilizada como nó separador, podendo levar a mais divisões impuras, requisitando novamente a execução do algoritmo.\n",
        "\n",
        "- Caso uma característica seja numérica contínua, seus valores são ordenados do menor para o maior, as médias entre valores adjacentes são obtidas e estas médias são utilizadas para calcular o gini do nó que faz \"característica numérica < valor\". O menor índice de gini para uma certa média faz com que tal média seja posta no lugar de \"valor\"."
      ],
      "metadata": {
        "id": "HlNY2ePEKb1P"
      },
      "id": "HlNY2ePEKb1P"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ede8c48d",
      "metadata": {
        "id": "ede8c48d"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_boston, load_iris\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iremos utilizar uma random tree para classificação no dataset **iris** e para regressão no **boston**."
      ],
      "metadata": {
        "id": "zggasbNIStT-"
      },
      "id": "zggasbNIStT-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificador com Random Tree"
      ],
      "metadata": {
        "id": "O3Q3s_rcS6vG"
      },
      "id": "O3Q3s_rcS6vG"
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size=0.2)"
      ],
      "metadata": {
        "id": "R92D3qqNSoxx"
      },
      "id": "R92D3qqNSoxx",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_preds = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "yXJ8TbGnTh5V"
      },
      "id": "yXJ8TbGnTh5V",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_preds)"
      ],
      "metadata": {
        "id": "UVY6kM53TsL0",
        "outputId": "2524a239-48d1-4cd7-85cf-3c1a8b908f4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UVY6kM53TsL0",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_preds)) # um modelo muito bom (dataset simples)"
      ],
      "metadata": {
        "id": "sn48bt9SU1r7",
        "outputId": "88e97d7b-a0ee-4734-dee3-8640cf6646e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sn48bt9SU1r7",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         9\n",
            "           1       0.89      1.00      0.94         8\n",
            "           2       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.96      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perceba que uma árvore de decisão possui determinada profundidade, que por padrão do scikit-learn é automática até que se obtenham nós puros. Isto pode ser um fator prejudicial, pois temos então uma grande chance de obter overfitting de dados. \n",
        "\n",
        "Por conta disso, fazemos um procedimento chamado de \"poda\", restrigindo a profundidade máxima da árvore de modo que a mesma aprenda apenas as características gerais dos dados de treino."
      ],
      "metadata": {
        "id": "M5XRpcPuYbil"
      },
      "id": "M5XRpcPuYbil"
    },
    {
      "cell_type": "code",
      "source": [
        "def score_classifier(X_train, X_test, y_train, y_test, max_depth=5):\n",
        "  classifier = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  classifier.fit(X_train, y_train)\n",
        "  return classifier.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "x307hUANZbst"
      },
      "id": "x307hUANZbst",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_depths = [2, 5, 7, 9, 11, 13, 15]\n",
        "\n",
        "for max_depth in max_depths:\n",
        "  score = score_classifier(X_train, X_test, y_train, y_test, max_depth)\n",
        "  print(f'Score: {score} for depht {max_depth}') # best depth -> 7 or 9 -> reduces overfitting"
      ],
      "metadata": {
        "id": "MjTBtQ96Y3MD",
        "outputId": "ef4fcb23-07bd-4c27-ce56-ca3fa26ebce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MjTBtQ96Y3MD",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.9666666666666667 for depht 2\n",
            "Score: 0.9333333333333333 for depht 5\n",
            "Score: 0.9333333333333333 for depht 7\n",
            "Score: 0.9333333333333333 for depht 9\n",
            "Score: 1.0 for depht 11\n",
            "Score: 0.9666666666666667 for depht 13\n",
            "Score: 0.9666666666666667 for depht 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regressor com Random Tree"
      ],
      "metadata": {
        "id": "2bZ_WsgMbCPg"
      },
      "id": "2bZ_WsgMbCPg"
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=13, test_size=13)"
      ],
      "metadata": {
        "id": "ZgjL934lbFnu",
        "outputId": "1729476d-9533-41c5-abb7-9c2a6aba34b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZgjL934lbFnu",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_preds = regressor.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_preds)\n",
        "print(mae)"
      ],
      "metadata": {
        "id": "OZ2mResGcZU9",
        "outputId": "6475b17c-bcd4-43ce-a6c6-d207321edd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OZ2mResGcZU9",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.392307692307693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def score_regression(X_train, X_test, y_train, y_test, max_depth=5):\n",
        "  regressor = DecisionTreeRegressor(max_depth=max_depth)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_preds = regressor.predict(X_test)\n",
        "  mae = mean_absolute_error(y_test, y_preds)\n",
        "  return mae"
      ],
      "metadata": {
        "id": "9mZLP_2tc8r0"
      },
      "id": "9mZLP_2tc8r0",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for max_depth in max_depths:\n",
        "  mae = score_regression(X_train, X_test, y_train, y_test, max_depth)\n",
        "  print(f'Max depth {max_depth} produces MAE {mae}') # -> best max depth: 2 -> reduces underfitting"
      ],
      "metadata": {
        "id": "Exzjp-y3dQ2j",
        "outputId": "16314a29-f3ae-4ea8-bc22-e1a74e1c01e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Exzjp-y3dQ2j",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max depth 2 produces MAE 2.79961753353119\n",
            "Max depth 5 produces MAE 3.4420449177051973\n",
            "Max depth 7 produces MAE 3.4877153188691636\n",
            "Max depth 9 produces MAE 2.9280490890688267\n",
            "Max depth 11 produces MAE 3.726768103691181\n",
            "Max depth 13 produces MAE 4.0628205128205135\n",
            "Max depth 15 produces MAE 3.596153846153847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Importances\n",
        "\n",
        "Podemos utilizar o atributo **feature_importances_** das decision trees para termos noção do quanto cada atributo (coluna do dataset) afeta a predição do modelo. Não é interessante retirar todas as características menos influentes de uma vez, e sim aos poucos, pois muitas características podem possuir certa correlação, podendo afetar mais as predições do modelo após alguma outra ser retirada."
      ],
      "metadata": {
        "id": "5BjgYcRZxhqu"
      },
      "id": "5BjgYcRZxhqu"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "metadata": {
        "id": "iIlRD9PIxhdX"
      },
      "id": "iIlRD9PIxhdX",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_breast_cancer(return_X_y=True)"
      ],
      "metadata": {
        "id": "JZeLXUDAyJTN"
      },
      "id": "JZeLXUDAyJTN",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "LH44ntA9ybmL",
        "outputId": "c8132edc-c958-4b30-cab1-3834c8f01ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LH44ntA9ybmL",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.feature_importances_"
      ],
      "metadata": {
        "id": "3nEAx22kye37",
        "outputId": "ffff11cb-be2c-4517-e5ec-1b2b906c4f54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3nEAx22kye37",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.00689159, 0.00877112, 0.03747995, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.00204521, 0.00100384,\n",
              "       0.        , 0.        , 0.00563858, 0.        , 0.        ,\n",
              "       0.69559352, 0.08856128, 0.        , 0.0110859 , 0.01440488,\n",
              "       0.        , 0.01411125, 0.10709688, 0.        , 0.007316  ])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Decision_Trees.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}